{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# l'Objectif du projet:\n",
    "* Prédire la qualité du vin vis-à-vis des consommateurs \n",
    "* Aider les consommateur à prendre une decision par rapport à la qualité du vin pour son utilisation\n",
    "* aider les entreprises fabricatrices à rendre la qualité du vin mailleur, en se basant sur les composant constituant le vin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De cette façon, nous allons:\n",
    "* importer les données\n",
    "* visualiser les données\n",
    "* faire une analyse exploratoire de ses données\n",
    "* tester les donnéesdonnées en les entraînant à des modèles d'entraînement de machin Learning\n",
    "* rendre lesdonnées explicite pour que les deux parties parviennent à prendre les décision qui les conviennent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous classifions nos données comme suit:\n",
    "* utilisons les colonne comme de variables à predir\n",
    "* choisisson parmis ces variables les mieux\n",
    "* utilison ces variables pour la prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voici nos variacbles:\n",
    "\n",
    " *  volatile acidity    \n",
    " *  citric acid         \n",
    " *  residual sugar      \n",
    " *  chlorides           \n",
    " *  free sulfur dioxide \n",
    " *  total sulfur dioxide\n",
    " *  density             \n",
    " *  pH                  \n",
    " *  sulphates           \n",
    " *  alcohol             \n",
    " *  quality\n",
    " \n",
    " On se base sur:  (residual sugar,  pH, quality) pour prédire la qualité de vin\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concretisation du projet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On importe toutes les bibliothèques naicessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from seaborn.axisgrid import plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On importe notre fichier de données pour faire les analyses possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire les données\n",
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "data = read_data('winequality-red.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Connaissance de lastructure de notre données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cette ligne de code calcule les fréquences relatives des différentes valeurs de la colonne quality dans le dataframe data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"quality\"].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats indiquent que la valeur la plus fréquente dans la colonne quality est 5, qui représente environ 42.6% des valeurs. La deuxième valeur la plus fréquente est 6, qui représente environ 39.9% des valeurs. Les autres valeurs (7, 4, 8 et 3) sont moins fréquentes et représentent respectivement environ 12.4%, 3.3%, 1.1% et 0.6% des valeurs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L'histogramme de chaque composant du vin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=(20,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consideron la meilleur qualité du vin est: qualité >= 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.quality >= 7].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mettons en relation les données pour mieux predire la meilleur qualité du vin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Le code suivant nous spécifie la corrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.catplot(data.corr())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# le code suivant:\n",
    "* nous affiche les données corrélées sous forme de cube corrélés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "mask = np.triu(np.ones_like(data.corr(), dtype=bool))\n",
    "sns.heatmap(data.corr(), mask=mask,center=0,cmap='RdBu', linewidths=1, annot=True)\n",
    "plt.title('Données corrélées ou Coefficient de corrélation')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cherchon les données manquantes pour les corrigées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *  cette fonction trouve les valeurs aberrantes dans un DataFrame pandas en utilisant la méthode des écarts interquartiles (IQR) et renvoie un nouveau DataFrame contenant toutes les lignes avec des valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(data):\n",
    "    outliers = pd.DataFrame(columns=data.columns)\n",
    "    for col in data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        col_outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
    "        outliers = pd.concat([outliers, col_outliers], axis=0)\n",
    "    return outliers.drop_duplicates()\n",
    "\n",
    "outliers = find_outliers(data)\n",
    "print(outliers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons le nombre des lignes et des colonnes des valeurs aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes contenant des valeurs aberrantes :434\n",
      "Nombre de colonne contenant des valeurs aberrantes : 5208\n"
     ]
    }
   ],
   "source": [
    "num_outlier_rows = outliers.shape[0]\n",
    "num_outlier_cols = outliers.count().sum()\n",
    "\n",
    "print(f'Nombre de lignes contenant des valeurs aberrantes :{num_outlier_rows}')\n",
    "print(f'Nombre de colonne contenant des valeurs aberrantes : {num_outlier_cols}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitons les valeurs aberrante s'ils existent\n",
    "Ce code calcule d’abord les premier et troisième quartiles des données, \n",
    "puis utilise ces valeurs pour calculer l’écart interquartile (IQR).\n",
    "Ensuite, il définit une limite inférieure et supérieure pour détecter les valeurs aberrantes\n",
    "en utilisant la formule lower_bound = Q1 - 1.5 * IQR et upper_bound = Q3 + 1.5 * IQR.\n",
    "Enfin, il remplace les valeurs aberrantes par la médiane des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data):\n",
    "    # Calculer le premier et le troisième quartile\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    \n",
    "    # Calculer l'écart interquartile (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Définir la limite inférieure et supérieure pour détecter les valeurs aberrantes\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Remplacer les valeurs aberrantes par la médiane\n",
    "    data[data < lower_bound] = np.median(data)\n",
    "    data[data > upper_bound] = np.median(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = remove_outliers(data)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les etapes utilisés pour analyser nos données dand le fichier data:\n",
    "\n",
    "* Charger les données: \n",
    "On a utilisé la binliothèque pandas pour charger les données à partir du fichier data dans un dataframe.\n",
    "\n",
    "* Examiner la structure des données: \n",
    "On utilise en suite head(), tail, describe et info, pour examiner la structure des données, y compris le nombre de lignes et de colonnes, les types de données et les statistiques descriptives de base.\n",
    "\n",
    "* Nettoyer les données: \n",
    "Ensuite on a effectué des étapes de nettoyage des données pour traiter les valeurs manquantes, les erreurs et les anomalies dans les données.\n",
    "\n",
    "* Visualiser les données: \n",
    "On a utilisé des bibliothèques de visualisation telles que matplotlib ou seaborn pour créer des graphiques et des visualisations pour explorer les données et examiner les relations entre les variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse exploratoire des données\n",
    "def describe_data(data):\n",
    "    print(data.describe())\n",
    "describe_data(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le code suivant nous permet la visualisation de données.\n",
    "la visualisation est un outil puissant pour l’exploration et l’analyse des données, ainsi que pour la communication des résultats d’une analyse. Elle peut aider à prendre des décisions éclairées en fournissant une compréhension claire et visuelle des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des données\n",
    "def plot_data(data):\n",
    "    sns.barplot(data)\n",
    "    \n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(\"Les données concernant la qualité du vin par rapport aux composants\")\n",
    "plot_data(data)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante, appelée split_data, prend en entrée trois arguments: data, target_column et test_size. data représente un DataFrame pandas contenant les données à diviser en ensembles d’entraînement et de test. target_column est le nom de la colonne dans data qui contient les valeurs de la variable cible (ou dépendante). test_size est un nombre décimal entre 0 et 1 qui représente la proportion des données à utiliser pour l’ensemble de test. La valeur par défaut de test_size est 0.2, ce qui signifie que 20% des données seront utilisées pour l’ensemble de test et 80% pour l’ensemble d’entraînement.\n",
    "\n",
    "* La fonction commence par séparer les données en variables indépendantes (ou caractéristiques) et variable dépendante (ou cible). Les variables indépendantes sont stockées dans X, qui est créé en supprimant la colonne target_column du DataFrame d’entrée data. La variable dépendante est stockée dans y, qui est créée en sélectionnant uniquement la colonne target_column du DataFrame d’entrée data.\n",
    "\n",
    "* Ensuite, la fonction utilise la fonction train_test_split du module sklearn.model_selection pour diviser les données en ensembles d’entraînement et de test. Les arguments d’entrée de cette fonction sont les variables indépendantes (X), la variable dépendante (y) et la taille de l’ensemble de test (test_size). La fonction renvoie quatre tableaux: les variables indépendantes pour l’ensemble d’entraînement (X_train), les variables indépendantes pour l’ensemble de test (X_test), la variable dépendante pour l’ensemble d’entraînement (y_train) et la variable dépendante pour l’ensemble de test (y_test).\n",
    "\n",
    "* Enfin, la fonction renvoie ces quatre tableaux comme résultat. En résumé, cette fonction divise un DataFrame pandas en ensembles d’entraînement et de test pour les variables indépendantes et dépendantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modélisation\n",
    "def split_data(data, target_column, test_size=0.2):\n",
    "    X = data.drop(target_column, axis=1)\n",
    "    y = data[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appelle de lafonction split_data\n",
    "X_train, X_test, y_train, y_test = split_data(data, 'quality', test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La fonction 'train_model'  fonction entraîne un modèle de régression linéaire en utilisant \n",
    " les données d’entraînement fournies en entrée et renvoie le modèle entraîné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appelle de la fonction train\n",
    "model = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner et tester le modèle\n",
    "def Evaluation_modele(model, X_train, X_test, y_train, y_test):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35428488856231544, 0.3504229724199335)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Appelle de la fonction Evaluation\n",
    "train_score, test_score = Evaluation_modele(model, X_train, X_test, y_train, y_test)\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Le score d’entraînement du modèle est: {train_score}')\n",
    "print(f'Le score de test du modèle est: {test_score}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# le score d’entraînement du modèle est de 0.35 et le score de test est également de 0.35. Cela indique que le modèle a une performance similaire sur les données d’entraînement et de test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afficher les prédictions du modèle en utilisant la méthode predict du modèle sur les données de test X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les valeurs de MSE et MAE sont respectivement de 0.44 et 0.53, ce qui indique que les prédictions du modèle ont une erreur moyenne d’environ 0.44 et 0.53 par rapport aux étiquettes réelles. La valeur de R² est de 0.35, ce qui indique que les prédictions du modèle s’ajustent modérément bien aux données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('R²:', r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
